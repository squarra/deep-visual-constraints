{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4140831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import trimesh\n",
    "\n",
    "from dcv.dataset import PIFODataset, RandomImageWarper\n",
    "from dcv.feature import SDF_Feature\n",
    "from dcv.frame import Frame\n",
    "from dcv.utils import to_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64e20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# exp_name = 'noPixelAligned_best'\n",
    "exp_name = \"PIFO_best\"\n",
    "state = torch.load(\"network/\" + exp_name + \".pth.tar\", map_location=torch.device(\"cpu\") if device == \"cpu\" else None)\n",
    "C = state[\"config\"]\n",
    "\n",
    "trainset = PIFODataset(\n",
    "    C[\"DATA_FILENAME\"],\n",
    "    num_views=C[\"NUM_VIEWS\"],\n",
    "    num_points=C[\"NUM_POINTS\"],\n",
    "    num_grasps=C[\"NUM_GRASPS\"],\n",
    "    num_hangs=C[\"NUM_HANGS\"],\n",
    "    grasp_draw_points=C[\"GRASP_DRAW_POINTS\"],\n",
    "    hang_draw_points=C[\"HANG_DRAW_POINTS\"],\n",
    "    random_erase=False,\n",
    "    on_gpu_memory=(device == \"cuda\"),\n",
    ")\n",
    "# trainset.show_data(0)\n",
    "testset = PIFODataset(\n",
    "    \"data/test_batch.hdf5\",\n",
    "    num_views=C[\"NUM_VIEWS\"],\n",
    "    num_points=C[\"NUM_POINTS\"],\n",
    "    num_grasps=C[\"NUM_GRASPS\"],\n",
    "    num_hangs=C[\"NUM_HANGS\"],\n",
    "    grasp_draw_points=C[\"GRASP_DRAW_POINTS\"],\n",
    "    hang_draw_points=C[\"HANG_DRAW_POINTS\"],\n",
    "    random_erase=False,\n",
    "    on_gpu_memory=(device == \"cuda\"),\n",
    ")\n",
    "warper = RandomImageWarper(img_res=C[\"IMG_RES\"])\n",
    "\n",
    "# Model\n",
    "obj = Frame()\n",
    "obj.build_backbone(pretrained=True, **C)\n",
    "obj.build_sdf_head(C[\"SDF_HEAD_HIDDEN\"])\n",
    "obj.build_keypoint_head(\"grasp\", C[\"GRASP_HEAD_HIDDEN\"], C[\"GRIPPER_POINTS\"])\n",
    "obj.build_keypoint_head(\"hang\", C[\"HANG_HEAD_HIDDEN\"], C[\"HOOK_POINTS\"])\n",
    "obj.load_state_dict(state[\"network\"])\n",
    "obj.to(device).eval()\n",
    "F_sdf = SDF_Feature(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad984a1-e819-4951-8893-0809e3dcaec5",
   "metadata": {},
   "source": [
    "# PCA on image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd82aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = testset\n",
    "dataset = trainset\n",
    "\n",
    "rgb_list, extrinsic_list, intrinsic_list = [], [], []\n",
    "for ind in range(10, 19):\n",
    "    data = to_device(dataset[ind], device)\n",
    "    rgb_list.append(data[\"rgb\"])\n",
    "    extrinsic_list.append(data[\"cam_extrinsic\"])\n",
    "    intrinsic_list.append(data[\"cam_intrinsic\"])\n",
    "\n",
    "rgb, projections = warper(torch.stack(rgb_list, dim=0), torch.stack(extrinsic_list, dim=0), torch.stack(intrinsic_list, dim=0))\n",
    "with torch.no_grad():\n",
    "    obj.backbone.encode(rgb, projections)\n",
    "\n",
    "features = obj.backbone.img_features.permute(0, 2, 3, 1).contiguous()\n",
    "feat_dim = features.shape[-1]\n",
    "U, S, V = torch.pca_lowrank(features.view(-1, feat_dim))\n",
    "num_colors = 5\n",
    "colors = torch.matmul(features.view(-1, feat_dim), V[:, :num_colors])  # (B*num_views*64*64, 3)\n",
    "\n",
    "colors -= colors.min(dim=0, keepdim=True)[0]\n",
    "colors /= colors.max(dim=0, keepdim=True)[0]\n",
    "\n",
    "# colors -= colors.mean(dim=0,keepdim=True)\n",
    "# colors /= 2.*colors.std(dim=0,keepdim=True)\n",
    "# colors += 0.5\n",
    "# colors.clamp_(0,1)\n",
    "\n",
    "num_views = obj.backbone.num_views\n",
    "colors = colors.view(-1, num_views, 64, 64, num_colors).cpu()\n",
    "\n",
    "for b in range(colors.shape[0]):\n",
    "    plt.figure(figsize=(6, 10))\n",
    "    for n in range(num_views):\n",
    "        img = rgb[b, n].permute(1, 2, 0).cpu()\n",
    "\n",
    "        plt.subplot(1 + num_colors, num_views, n + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        for c in range(num_colors):\n",
    "            plt.subplot(1 + num_colors, num_views, (c + 1) * num_views + n + 1)\n",
    "            plt.imshow(colors[b, n, :, :, c])\n",
    "            plt.axis(\"off\")\n",
    "    #     plt.savefig(\"feat\"+str(b)+\".pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0836f9-f11d-456d-97dd-6258856c36b9",
   "metadata": {},
   "source": [
    "# PCA on surface representation vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2697e9-757d-44c7-84b3-069c48835f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = trainset\n",
    "# dataset = testset\n",
    "\n",
    "inds = list(range(0, 9))\n",
    "# inds = [20]*9\n",
    "B, N = len(inds), 1000\n",
    "\n",
    "points, img, projection = [], [], []\n",
    "for ind in inds:\n",
    "    data = dataset[ind]\n",
    "\n",
    "    mesh_filename = path.join(\"data/meshes\", data[\"filenames\"].decode())\n",
    "    object_trimesh = trimesh.load(mesh_filename)\n",
    "    points.append(torch.Tensor(object_trimesh.sample(N)).to(device))\n",
    "\n",
    "    rgb, projections = warper(data[\"rgb\"].unsqueeze(0), data[\"cam_extrinsic\"].unsqueeze(0), data[\"cam_intrinsic\"].unsqueeze(0))\n",
    "    img.append(rgb.squeeze(0))\n",
    "    projection.append(projections.squeeze(0))\n",
    "\n",
    "points = torch.stack(points, dim=0)\n",
    "img = torch.stack(img, dim=0)\n",
    "projection = torch.stack(projection, dim=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    features = obj.backbone(points, img, projection).mean(dim=1)\n",
    "\n",
    "\n",
    "feat_dim = features.shape[-1]\n",
    "U, S, V = torch.pca_lowrank(features.view(-1, feat_dim))\n",
    "num_color = 1\n",
    "start = 0\n",
    "colors = torch.matmul(features.view(-1, feat_dim), V[:, start : start + num_color])\n",
    "\n",
    "colors -= colors.min(dim=0, keepdim=True)[0]\n",
    "colors /= colors.max(dim=0, keepdim=True)[0]\n",
    "\n",
    "colors = colors.view(B, N, num_color).detach().cpu().numpy()\n",
    "fig = plt.figure()\n",
    "for i, point in enumerate(points):\n",
    "    ax = plt.subplot(B // 3, 3, i + 1, projection=\"3d\")\n",
    "    point = point.cpu().numpy()\n",
    "    if num_color == 1:\n",
    "        ax.scatter(point[:, 0], point[:, 1], point[:, 2], c=colors[i])\n",
    "    else:\n",
    "        ax.scatter(point[:, 0], point[:, 1], point[:, 2], color=colors[i])\n",
    "\n",
    "    ax.set_xlim([-0.1, 0.1])\n",
    "    ax.set_ylim([-0.1, 0.1])\n",
    "    ax.set_zlim([-0.1, 0.1])\n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-visual-constraints",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
