{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c8735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from dcv.dataset import PIFODataset, RandomImageWarper\n",
    "from dcv.feature import KeyPoint_Feature\n",
    "from dcv.frame import Frame\n",
    "from dcv.utils import random_quaternions, to_device, view_scene_grasp_batch, view_scene_hang_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2119ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "exp_name = \"PIFO_best\"\n",
    "# exp_name = 'noPixelAligned_best'\n",
    "state = torch.load(\"network/\" + exp_name + \".pth.tar\", map_location=torch.device(\"cpu\") if device == \"cpu\" else None)\n",
    "C = state[\"config\"]\n",
    "\n",
    "trainset = PIFODataset(\n",
    "    C[\"DATA_FILENAME\"],\n",
    "    num_views=C[\"NUM_VIEWS\"],\n",
    "    num_points=C[\"NUM_POINTS\"],\n",
    "    num_grasps=C[\"NUM_GRASPS\"],\n",
    "    num_hangs=C[\"NUM_HANGS\"],\n",
    "    grasp_draw_points=C[\"GRASP_DRAW_POINTS\"],\n",
    "    hang_draw_points=C[\"HANG_DRAW_POINTS\"],\n",
    "    random_erase=False,\n",
    "    on_gpu_memory=(device == \"cuda\"),\n",
    ")\n",
    "testset = PIFODataset(\n",
    "    \"data/test_batch.hdf5\",\n",
    "    num_views=C[\"NUM_VIEWS\"],\n",
    "    num_points=C[\"NUM_POINTS\"],\n",
    "    num_grasps=C[\"NUM_GRASPS\"],\n",
    "    num_hangs=C[\"NUM_HANGS\"],\n",
    "    grasp_draw_points=C[\"GRASP_DRAW_POINTS\"],\n",
    "    hang_draw_points=C[\"HANG_DRAW_POINTS\"],\n",
    "    random_erase=False,\n",
    "    on_gpu_memory=(device == \"cuda\"),\n",
    ")\n",
    "warper = RandomImageWarper(img_res=C[\"IMG_RES\"])\n",
    "# Model\n",
    "obj = Frame()\n",
    "obj.build_backbone(pretrained=True, **C)\n",
    "obj.build_sdf_head(C[\"SDF_HEAD_HIDDEN\"])\n",
    "obj.build_keypoint_head(\"grasp\", C[\"GRASP_HEAD_HIDDEN\"], C[\"GRIPPER_POINTS\"])\n",
    "obj.build_keypoint_head(\"hang\", C[\"HANG_HEAD_HIDDEN\"], C[\"HOOK_POINTS\"])\n",
    "obj.load_state_dict(state[\"network\"])\n",
    "obj.to(device).eval()\n",
    "F_grasp = KeyPoint_Feature(obj, \"grasp\")\n",
    "F_hang = KeyPoint_Feature(obj, \"hang\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23868aa0-4c7a-4c2e-b429-7c1f86843f30",
   "metadata": {},
   "source": [
    "# Grasping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a6ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = trainset\n",
    "dataset = testset\n",
    "\n",
    "B, N = 2, 20\n",
    "rgb_list, projections_list, filename_list, mass_list, com_list = [], [], [], [], []\n",
    "for i in range(B):\n",
    "    data = to_device(dataset[i], device)\n",
    "    rgb, projections = warper(data[\"rgb\"].unsqueeze(0), data[\"cam_extrinsic\"].unsqueeze(0), data[\"cam_intrinsic\"].unsqueeze(0))\n",
    "    rgb_list.append(rgb)\n",
    "    projections_list.append(projections)\n",
    "    filename_list.append(data[\"filenames\"].decode())\n",
    "    mass_list.append(data[\"masses\"])\n",
    "    com_list.append(data[\"coms\"])\n",
    "\n",
    "x = torch.cat([0.2 * torch.randn(B, N, 3, device=device), random_quaternions(B * N, device=device).view(B, N, 4)], dim=2)\n",
    "\n",
    "print(\"Init poses\")\n",
    "view_scene_grasp_batch(x.cpu().numpy(), np.ones((B, N)), filename_list, False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8986a08-d165-4e03-9179-24f6443be569",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, cost, coll = F_grasp.optimize(x, torch.cat(rgb_list), torch.cat(projections_list))\n",
    "x, cost, coll = F_grasp.optimize(x, torch.cat(rgb_list), torch.cat(projections_list), w_coll=1e3)\n",
    "\n",
    "num_best = 5\n",
    "best_inds = torch.tensor(cost + coll * 100.0).argsort(dim=1)[:, :num_best].to(device).view(B, num_best, 1).expand(-1, -1, 7)\n",
    "best_poses = torch.gather(x, dim=1, index=best_inds)\n",
    "f = np.zeros((B, N))\n",
    "\n",
    "print(\"optimized\")\n",
    "view_scene_grasp_batch(best_poses.cpu().numpy(), np.ones((B, num_best)), filename_list, False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfd63f5-b37b-4eaf-9816-ee50d37b9f69",
   "metadata": {},
   "source": [
    "# Hanging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cfb754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = trainset\n",
    "dataset = testset\n",
    "\n",
    "B, N = 2, 20\n",
    "rgb_list, projections_list, filename_list, mass_list, com_list = [], [], [], [], []\n",
    "for i in range(B):\n",
    "    data = to_device(dataset[i], device)\n",
    "    rgb, projections = warper(data[\"rgb\"].unsqueeze(0), data[\"cam_extrinsic\"].unsqueeze(0), data[\"cam_intrinsic\"].unsqueeze(0))\n",
    "    rgb_list.append(rgb)\n",
    "    projections_list.append(projections)\n",
    "    filename_list.append(data[\"filenames\"].decode())\n",
    "    mass_list.append(data[\"masses\"])\n",
    "    com_list.append(data[\"coms\"])\n",
    "\n",
    "x = torch.cat([0.2 * torch.randn(B, N, 3, device=device), random_quaternions(B * N, device=device).view(B, N, 4)], dim=2)\n",
    "\n",
    "print(\"Init poses\")\n",
    "view_scene_hang_batch(x.cpu().numpy(), np.ones((B, N)), filename_list).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239bf30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, cost, coll = F_hang.optimize(x, torch.cat(rgb_list), torch.cat(projections_list))\n",
    "x, cost, coll = F_hang.optimize(x, torch.cat(rgb_list), torch.cat(projections_list), w_coll=1e2, coll_margin=1e-8)\n",
    "\n",
    "num_best = 5\n",
    "best_inds = torch.tensor(cost).argsort(dim=1)[:, :num_best].to(device).view(B, num_best, 1).expand(-1, -1, 7)\n",
    "best_poses = torch.gather(x, dim=1, index=best_inds)\n",
    "\n",
    "print(\"optimized\")\n",
    "view_scene_hang_batch(best_poses.cpu().numpy(), np.ones((B, N)), filename_list).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-visual-constraints",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
